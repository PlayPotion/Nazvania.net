import tkinter as tk
from tkinter import ttk, messagebox
from PIL import Image, ImageTk
from mediapipe import solutions
from mediapipe.framework.formats import landmark_pb2
import cv2
import numpy as np
import datetime
import os
import time
from threading import Thread
from bez_mata.config import SCREENS_DIR, CAMERA_INDEX, FRAME_WIDTH, FRAME_HEIGHT, BLUE, RED, GREEN, GESTURE_CONTROL_ENABLED
from bez_mata.core.face_detection import FaceDetector
from bez_mata.core.face_recognition import FaceRecognizer
from bez_mata.core.gesture_control import GestureRecognizer
from bez_mata.db.face_db import FaceDB


class MainApp(tk.Tk):
    def __init__(self):
        super().__init__()
        self.title("Nazvania.net")
        self.geometry("1200x800")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        try:
            self.face_detector = FaceDetector()
            self.face_recognizer = FaceRecognizer()
            self.gesture_recognizer = GestureRecognizer()
            self.face_db = FaceDB(self.face_recognizer)
        except Exception as e:
            self._show_init_error(e)
            return

        # –í–∞—Ä–∏–∞—Ç–∏–≤–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏
        self.last_screenshot = None
        self.last_screenshot_faces = []
        self.last_screenshot_embeddings = []
        self.running = True
        self.highlight_mode = False
        self.access_control_mode = False
        self.gesture_control_enabled = GESTURE_CONTROL_ENABLED

        # –°–æ–∑–¥–∞–Ω–∏–µ UI
        self._setup_ui()

        # –ó–∞–ø—É—Å–∫ –≤–∏–¥–µ–æ
        self.cap = cv2.VideoCapture(CAMERA_INDEX)
        if not self.cap.isOpened():
            self._show_camera_error()
            return

        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_WIDTH)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT)

        # –ó–∞–ø—É—Å–∫ –≤–∏–¥–µ–æ
        self.video_thread = Thread(target=self._video_loop)
        self.video_thread.daemon = True
        self.video_thread.start()

        if GESTURE_CONTROL_ENABLED:
            self.gesture_recognizer.enable()
        else:
            self.gesture_recognizer.disable()

    def _show_camera_error(self):
        messagebox.showerror("–û—à–∏–±–∫–∞ –∫–∞–º–µ—Ä—ã", "–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ")
        self.destroy()

    def _show_init_error(self, error):
        messagebox.showerror("–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏", f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤:\n{str(error)}")
        if hasattr(self, 'cap'):
            self.cap.release()
        self.destroy()

    def _setup_ui(self):
        """ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞"""
        # –í–∏–¥–µ–æ–∫–∞–¥—Ä—ã
        self.video_frame = ttk.Label(self)
        self.video_frame.pack(pady=10)

        # –ö–Ω–æ–ø–∫–∏ –∫–æ–Ω—Ç—Ä–æ–ª—è
        control_frame = ttk.Frame(self)
        control_frame.pack(pady=10)

        # –°–æ–∑–¥–∞–µ–º —Å—Ç–∏–ª—å –¥–ª—è –∫–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∂–µ—Å—Ç–∞–º–∏
        self.style = ttk.Style()
        self.style.configure('Toggle.TButton',
                             foreground='freen' if GESTURE_CONTROL_ENABLED else 'red')

        # –ö–Ω–æ–ø–∫–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∂–µ—Å—Ç–∞–º–∏
        self.gesture_btn = ttk.Button(
            control_frame,
            text=f"–ñ–µ—Å—Ç—ã ({'ON' if GESTURE_CONTROL_ENABLED else 'OFF'})",
            command=self._toggle_gesture_control,
            style='Toggle.TButton'
        )
        self.gesture_btn.pack(side=tk.LEFT, padx=5)

        # –ö–Ω–æ–ø–∫–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–∫—Ä–∏–Ω—à–æ—Ç–∞–º–∏
        self.screenshot_btn = ttk.Button(
            control_frame,
            text="–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç (üëç)",
            command=self._take_screenshot
        )
        self.screenshot_btn.pack(side=tk.LEFT, padx=5)

        # –ö–Ω–æ–ø–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å –ø–æ—Å–ª–µ–¥–Ω–∏–º —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–º
        self.highlight_btn = ttk.Button(
            control_frame,
            text="–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–∏—è (‚úåÔ∏è)",
            command=self._toggle_highlight
        )
        self.highlight_btn.pack(side=tk.LEFT, padx=5)

        # –ö–Ω–æ–ø–∫–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–æ—Å—Ç—É–ø–æ–º
        self.access_btn = ttk.Button(
            control_frame,
            text="–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–æ—Å—Ç—É–ø–∞",
            command=self._toggle_access_control
        )
        self.access_btn.pack(side=tk.LEFT, padx=5)

        # –ö–Ω–æ–ø–∫–∞ –≤—ã—Ö–æ–¥–∞
        self.exit_btn = ttk.Button(
            control_frame,
            text="–í—ã—Ö–æ–¥ (‚òùÔ∏è)",
            command=self._exit_app
        )
        self.exit_btn.pack(side=tk.LEFT, padx=5)

        # –°—Ç–∞—Ç—É—Å –±–∞—Ä
        self.status_var = tk.StringVar()
        self.status_var.set("–ì–æ—Ç–æ–≤–æ")
        status_bar = ttk.Label(self, textvariable=self.status_var)
        status_bar.pack(fill=tk.X, pady=5)

        # –°—Ç–∞—Ç—É—Å –¥–æ—Å—Ç—É–ø–∞
        self.access_status_var = tk.StringVar()
        self.access_status_var.set("–î–æ—Å—Ç—É–ø: -")
        access_status = ttk.Label(self, textvariable=self.access_status_var, font=('Arial', 14))
        access_status.pack(fill=tk.X, pady=5)

    def _video_loop(self):
        """ –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ"""
        while self.running:
            try:
                ret, frame = self.cap.read()
                if not ret or frame is None:
                    time.sleep(0.1)
                    continue

                # –°–æ–∑–¥–∞—ë–º –∫–æ–ø–∏—é –∫–∞–¥—Ä–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
                processed_frame = frame.copy()

                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ª–∏—Ü
                faces = []
                try:
                    faces = self.face_detector.detect_faces(frame)
                    self.status_var.set(f"–õ—é–¥–µ–π –≤ –∫–∞–¥—Ä–µ: {len(faces)}")
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ª–∏—Ü: {e}")

                try:
                    if self.access_control_mode:
                        processed_frame = self._process_access_control(frame.copy(), faces)
                    else:
                        processed_frame = self._process_frame(frame.copy())
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –≤–∏–¥–µ–æ–ø—Ä–æ—Ü–µ—Å—Å–∞: {e}")
                    processed_frame = frame

                # –ü—Ä–æ—Ü–µ—Å—Å –∫–∞–¥—Ä–æ–≤
                if self.access_control_mode:
                    frame = self._process_access_control(frame, self.face_detector.detect_faces(frame))
                processed_frame = self._process_frame(frame.copy())

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –∂–µ—Å—Ç—ã
                if self.gesture_control_enabled:
                    try:
                        gesture, gesture_frame = self.gesture_recognizer.recognize(processed_frame)
                        processed_frame = gesture_frame # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–¥—Ä —Å –æ—Ç—Ä–∏—Å–æ–≤–∞–Ω–Ω—ã–º–∏ landmarks

                        if gesture == 'good':
                            self._take_screenshot()
                        elif gesture == 'v':
                            self._toggle_highlight()
                        elif gesture == 'ai':
                            self._exit_app()
                    except Exception as e:
                        print(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∂–µ—Å—Ç–æ–≤: {e}")

                # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                img = Image.fromarray(cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB))
                imgtk = ImageTk.PhotoImage(image=img)
                self.video_frame.config(image=imgtk)
                self.video_frame.image = imgtk

            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –≤–∏–¥–µ–æ–ø–æ—Ç–æ–∫–∞: {e}")
                time.sleep(0.5)

    def _process_frame(self, frame: np.ndarray) -> np.ndarray:
        """ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –ª–∏—Ü"""
        faces = self.face_detector.detect_faces(frame)
        self.status_var.set(f"–õ—é–¥–µ–π –≤ –∫–∞–¥—Ä–µ: {len(faces)}")

        # –õ–æ–≥–∏–∫–∞ –¥–æ—Å—Ç—É–ø–∞
        if self.access_control_mode and faces:
            self._process_access_control(frame, faces)

        # –õ–æ–≥–∏–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        if self.highlight_mode and self.last_screenshot is not None:
            frame = self._highlight_faces(frame, faces)

        # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–æ–≤
        for (x, y, w, h) in faces:
            color = GREEN if not (self.highlight_mode or self.access_control_mode) else BLUE
            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)

        return frame

    def _process_access_control(self, frame, faces):
        """ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ª–∏—Ü —Å –ª–∏—Ü–∞–º–∏ –≤ –±–∞–∑–µ –∏ –≤—ã–≤–æ–¥"""
        if frame is None:
            self.access_status_var.set("–û—à–∏–±–∫–∞: –ù–µ—Ç –∫–∞–¥—Ä–∞")
            return frame

        if not faces:
            self.access_status_var.set("–î–æ—Å—Ç—É–ø: –ù–µ—Ç –ª–∏—Ü")
            return frame

        access_granted = False
        recognized_name = None

        for (x, y, w, h) in faces:
            try:
                face_img = frame[y:y+h, x:x+w].copy()

                name = self.face_db.find_match(face_img)

                if name:
                    cv2.rectangle(frame, (x, y), (x+w, y+h), GREEN, 2)
                    cv2.putText(frame, f"Access {name}", (x, y-10),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, GREEN, 2)
                    recognized_name = name
                    access_granted = True
                    break
                else:
                    cv2.rectangle(frame, (x, y), (x+w, y+h), RED, 2)

            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ª–∏—Ü–∞: {e}")
                continue

        if access_granted:
            self.access_status_var.set(f"–î–æ—Å—Ç—É–ø: {recognized_name}")
        else:
            cv2.putText(frame, "–í –¥–æ—Å—Ç—É–ø–µ –æ—Ç–∫–∞–∑–∞–Ω–æ", (50, 50),
                        cv2.FONT_HERSHEY_SIMPLEX, 1, RED, 2)
            self.access_status_var.set("–î–æ—Å—Ç—É–ø: –æ—Ç–∫–ª–æ–Ω—ë–Ω")

        return frame

    def _highlight_faces(self, frame, current_faces):
        """ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ª–∏—Ü —Å –ø–æ—Å–ª–µ–¥–Ω–∏–º —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–º"""
        for (x, y, w, h) in current_faces:
            face_img = frame[y:y + h, x:x + w]
            current_embedding = self.face_recognizer.get_embedding(face_img)
            is_new = True

            for saved_embedding in self.last_screenshot_embeddings:
                if self.face_recognizer.compare_faces(current_embedding, saved_embedding):
                    is_new = False
                    break

            color = RED if is_new else BLUE
            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 3)
            label = "New" if is_new else "Known"
            cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)

        return frame

    def _toggle_gesture_control(self):
        """ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Ä–µ–∂–∏–º–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∂–µ—Å—Ç–æ–≤ —Å –≤–∏–∑—É–∞–ª—å–Ω–æ–π –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑—å—é"""
        self.gesture_control_enabled = not self.gesture_control_enabled

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –∂–µ—Å—Ç–æ–≤
        if self.gesture_control_enabled:
            self.gesture_recognizer.enable()
            self.style.configure('Toggle.TButton', foreground='green')
        else:
            self.gesture_recognizer.disable()
            self.style.configure('Toggle.TButton', foreground='red')

        # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –∫–Ω–æ–ø–∫–∏
        state = "ON" if self.gesture_control_enabled else "OFF"
        self.gesture_btn.config(text=f"–ö–æ–Ω—Ç—Ä–æ–ª—å –∂–µ—Å—Ç–æ–≤ ({state})")

         # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–ø–ª—ã–≤–∞—é—â–µ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
        messagebox.showinfo(
            "–ö–æ–Ω—Ç—Ä–æ–ª—å –∂–µ—Å—Ç–æ–≤",
            f"–†–µ–∂–∏–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∂–µ—Å—Ç–æ–≤: {state}\n"
            f"üëç - —Å–∫—Ä–∏–Ω—à–æ—Ç\n‚úåÔ∏è - —Å—Ä–µ–≤–Ω–µ–Ω–∏–µ\n‚òùÔ∏è - –≤—ã—Ö–æ–¥"
        )

    def _take_screenshot(self):
        """ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∫–∞–¥—Ä–∞ –∫–∞–∫ —Å–∫—Ä–∏–Ω—à–æ—Ç"""
        ret, frame = self.cap.read()
        if not ret:
            return

        faces = self.face_detector.detect_faces(frame)
        self.last_screenshot_embeddings = []

        for (x, y, w, h) in faces:
            face_img = frame[y:y + h, x:x + w]
            embedding = self.face_recognizer.get_embedding(face_img)
            self.last_screenshot_embeddings.append(embedding)

        os.makedirs(SCREENS_DIR, exist_ok=True)
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        filename = f"{timestamp}_{len(faces)}.jpg"
        filepath = os.path.join(SCREENS_DIR, filename)
        cv2.imwrite(filepath, frame)

        self.last_screenshot = frame
        messagebox.showinfo("–°–∫—Ä–∏–Ω—à–æ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω", f"–°–∫—Ä–∏–Ω—à–æ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –∫–∞–∫ {filename}")

    def _toggle_highlight(self):
        """ –ê–∫—Ç–∏–≤–∞—Ü–∏—è —Ä–µ–∂–∏–º–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        self.highlight_mode = not self.highlight_mode
        state = "ON" if self.highlight_mode else "OFF"
        messagebox.showinfo("–†–µ–∂–∏–º —Å—Ä–∞–≤–Ω–µ–Ω–∏—è", f"–†–µ–∂–∏–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ: {state}")

    def _toggle_access_control(self):
        """ –ê–∫—Ç–∏–≤–∞—Ü–∏—è —Ä–µ–∂–∏–º–∞ –¥–æ–ø—É—Å–∫–∞"""
        self.access_control_mode = not self.access_control_mode
        if self.access_control_mode:
            self.highlight_mode = False
        state = "ON" if self.access_control_mode else "OFF"
        messagebox.showinfo("–†–µ–∂–∏–º –¥–æ–ø—É—Å–∫–∞", f"–†–µ–∂–∏–º –¥–æ–ø—É—Å–∫–∞: {state}")

    def _exit_app(self):
        """ –û—á–∏—Å—Ç–∫–∞ –∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã –ø—Ä–æ–≥—Ä–∞–º–º—ã"""
        self.running = False
        self.quit()
        self.destroy()


if __name__ == "__main__":
    app = MainApp()
    app.mainloop()
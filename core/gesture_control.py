import mediapipe as mp
import numpy as np
import time
from typing import Optional, Tuple
import cv2


class GestureRecognizer:
    """ –ö–ª–∞—Å—Å –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∂–µ—Å—Ç–æ–≤ —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π kandmarks —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º MediaPipe Hands """

    def __init__(self):
        """ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –∂–µ—Å—Ç–æ–≤"""
        self.mp_hands = mp.solutions.hands
        self.hands = None # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—é
        self.active = False # –§–ª–∞–≥ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
        self.last_gesture_time = 0
        self.gesture_cooldown = 3  # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∂–µ—Å—Ç–∞–º–∏ (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö)
        self.mp_drawing = mp.solutions.drawing_utils
        self.mp_drawing_styles = mp.solutions.drawing_styles

    def enable(self):
        """ –ê–∫—Ç–∏–≤–∏—Ä—É–µ—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∂–µ—Å—Ç–æ–≤ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–µ—Ç–µ–∫—Ç–æ—Ä"""
        if self.hands is None:
            self.hands = self.mp_hands.Hands(
                static_image_mode=False,
                max_num_hands=1,
                min_detection_confidence=0.7,
                min_tracking_confidence=0.5
            )
        self.active = True

    def disable(self):
        """ –î–µ–∞–∫—Ç–∏–≤–∏—Ä—É–µ—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∏ –æ—Å–≤–æ–±–æ–∂–¥–∞–µ—Ç —Ä–µ—Å—É—Ä—Å—ã"""
        if self.hands is not None:
            self.hands.close()
            self.hands = None
        self.active = False


    def recognize(self, image: np.ndarray) -> Optional[str]:
        """ –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∂–µ—Å—Ç–æ–≤ + –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å landmarks"""
        if not self.active:
            return None, image.copy()

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∑–∞–¥–µ—Ä–∂–∫–∏ –º–µ–∂–¥—É –∂–µ—Å—Ç–∞–º–∏
        current_time = time.time()
        if current_time - self.last_gesture_time < self.gesture_cooldown:
            return None, image.copy()

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        if image is None or image.size == 0:
            return None, image.copy() if image is not None else None

        try:
            # –°–æ–∑–¥–∞—ë–º –∫–æ–ø–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –æ—Ç—Ä–∏—Å–æ–≤–∫–∏
            annotated_image = image.copy()
            gesture = None

            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ü–≤–µ—Ç–æ–≤–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –¥–ª—è MediaPipe
            results = self.hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))

            if results.multi_hand_landmarks:
                # –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ–º landmarks –∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
                for hand_landmarks in results.multi_hand_landmarks:
                    self.mp_drawing.draw_landmarks(
                        annotated_image,
                        hand_landmarks,
                        self.mp_hands.HAND_CONNECTIONS,
                        self.mp_drawing_styles.get_default_hand_landmarks_style(),
                        self.mp_drawing_styles.get_default_hand_connections_style()
                    )

                # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—É—é —Ä—É–∫—É
                landmarks = results.multi_hand_landmarks[0].landmark
                gesture = self._classify_gesture(landmarks)

                if gesture:
                    self.last_gesture_time = current_time
                    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º –∂–µ—Å—Ç–∞
                    cv2.putText(annotated_image, f"Gesture: {gesture}", (10, 30),
                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

            return gesture, annotated_image

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∂–µ—Å—Ç–∞: {e}")
            return None, image.copy()

    def _classify_gesture(self, landmarks) -> Optional[str]:
        """ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∂–µ—Å—Ç–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Ç–æ—á–∫–∞–º —Ä—É–∫–∏"""
        if len(landmarks) < 21:
            return None

        # –ü–æ–ª—É—á–∞–µ–º –Ω—É–∂–Ω—ã–µ —Ç–æ—á–∫–∏ —Ä—É–∫–∏
        thumb_tip = landmarks[4]
        index_tip = landmarks[8]
        middle_tip = landmarks[12]
        wrist = landmarks[0]

        # –ñ–µ—Å—Ç "üëç" (–±–æ–ª—å—à–æ–π –ø–∞–ª–µ—Ü –≤–≤–µ—Ä—Ö)
        if (self._is_finger_closed(landmarks, [8, 12, 16, 20]) and  # –í—Å–µ –ø–∞–ª—å—Ü—ã –∫—Ä–æ–º–µ –±–æ–ª—å—à–æ–≥–æ —Å–æ–≥–Ω—É—Ç—ã
                thumb_tip.y < wrist.y):  # –ë–æ–ª—å—à–æ–π –ø–∞–ª–µ—Ü –≤—ã—à–µ –∑–∞–ø—è—Å—Ç—å—è (–≤–≤–µ—Ä—Ö)
            return 'good'

        # –ñ–µ—Å—Ç "‚úåÔ∏è" (–∑–Ω–∞–∫ V)
        if (self._is_finger_open(landmarks, [8, 12]) and  # –£–∫–∞–∑–∞—Ç–µ–ª—å–Ω—ã–π –∏ —Å—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–æ–≥–Ω—É—Ç—ã
                self._is_finger_closed(landmarks, [16, 20])):  # –ë–µ–∑—ã–º—è–Ω–Ω—ã–π –∏ –º–∏–∑–∏–Ω–µ—Ü —Å–æ–≥–Ω—É—Ç—ã
            return 'v'

        # –ñ–µ—Å—Ç "‚òùÔ∏è" (—É–∫–∞–∑–∞—Ç–µ–ª—å–Ω—ã–π –ø–∞–ª–µ—Ü –≤–≤–µ—Ä—Ö)
        if (self._is_finger_open(landmarks, [8]) and
                self._is_finger_closed(landmarks, [4, 12, 16, 20])):
            return 'ai'

        return None

    @staticmethod
    def _distance(p1, p2) -> float:
        """ –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –µ–≤–∫–ª–∏–¥–æ–≤–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –º–µ–∂–¥—É –¥–≤—É–º—è —Ç–æ—á–∫–∞–º–∏"""
        return ((p1.x - p2.x) ** 2 + (p1.y - p2.y) ** 2) ** 0.5

    @staticmethod
    def _is_finger_closed(landmarks, finger_tips) -> bool:
        """ –ü—Ä–æ–≤–µ—Ä–∫–∞, —Å–æ–≥–Ω—É—Ç –ª–∏ –ø–∞–ª–µ—Ü (—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –Ω–∏–∂–µ–ª–µ–∂–∞—â–∏–º —Å—É—Å—Ç–∞–≤–æ–º)"""
        for tip in finger_tips:
            tip = int(tip)
            if landmarks[tip].y < landmarks[tip - 2].y:
                return False
        return True

    @staticmethod
    def _is_finger_open(landmarks, finger_tips) -> bool:
        """ –ü—Ä–æ–≤–µ—Ä–∫–∞, —Ä–∞–∑–æ–≥–Ω—É—Ç –ª–∏ –ø–∞–ª–µ—Ü"""
        for tip in finger_tips:
            tip = int(tip)
            if landmarks[tip].y > landmarks[tip - 2].y:
                return False
        return True